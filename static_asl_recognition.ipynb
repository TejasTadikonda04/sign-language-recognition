{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7101ce",
   "metadata": {},
   "source": [
    "# Phase 1: Static ASL Training & Ablations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04658da7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b7a9167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard PyTorch + Torchvision stack\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# Reproducibility (essential for research and debugging)\n",
    "import random\n",
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Note: For complete reproducibility, you may also need:\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device (GPU if available)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', DEVICE)\n",
    "\n",
    "# Loading data\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e60a50",
   "metadata": {},
   "source": [
    "### ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fee650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet-18\n",
    "res18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf555d27",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc9f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet channel-wise statistics (computed over millions of images)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]  # Mean per channel (R, G, B)\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]  # Std dev per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7522a848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'asl-alphabet' dataset.\n",
      " Dataset: 116 train, 29 val\n",
      " Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "SEED = 429\n",
    "LIMIT_PER_CLASS = 5\n",
    "\n",
    "# Download data\n",
    "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
    "data_dir = os.path.join(path, \"asl_alphabet_train\", \"asl_alphabet_train\")\n",
    "\n",
    "# Training transforms\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Validation transforms\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "raw_dataset = datasets.ImageFolder(root=data_dir) \n",
    "\n",
    "# 5 images per class\n",
    "indices_to_use = []\n",
    "targets = np.array(raw_dataset.targets)\n",
    "classes = np.unique(targets)\n",
    "\n",
    "for cls in classes:\n",
    "    cls_indices = np.where(targets == cls)[0]\n",
    "    indices_to_use.extend(cls_indices[:LIMIT_PER_CLASS])\n",
    "\n",
    "# Get labels\n",
    "subset_labels = targets[indices_to_use]\n",
    "\n",
    "# 80/20 split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    indices_to_use, \n",
    "    test_size=0.2, \n",
    "    stratify=subset_labels, \n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "train_source = datasets.ImageFolder(root=data_dir, transform=train_tf)\n",
    "val_source   = datasets.ImageFolder(root=data_dir, transform=val_tf)\n",
    "\n",
    "# Final subsets\n",
    "full_train_source = datasets.ImageFolder(root=data_dir, transform=train_tf)\n",
    "full_val_source   = datasets.ImageFolder(root=data_dir, transform=val_tf)\n",
    "\n",
    "train_ds = Subset(full_train_source, train_idx)\n",
    "val_ds   = Subset(full_val_source, val_idx)\n",
    "\n",
    "train_ds.classes = train_source.classes\n",
    "val_ds.classes = val_source.classes\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "NUM_CLASSES = 29\n",
    "print(f' Dataset: {len(train_ds):,} train, {len(val_ds):,} val')\n",
    "print(f' Classes: {train_ds.classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd623e96",
   "metadata": {},
   "source": [
    "### Adapt ResNet-18 for ASL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb472cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original FC layer:\n",
      "  Input features: 512\n",
      "  Output features: 1000 (ImageNet classes)\n",
      "\n",
      " New FC layer:\n",
      "  Input features: 512\n",
      "  Output features: 29 (our classes)\n"
     ]
    }
   ],
   "source": [
    "# Start with ImageNet-pretrained weights\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Examine the original classifier\n",
    "print(\" Original FC layer:\")\n",
    "print(f\"  Input features: {model.fc.in_features}\")\n",
    "print(f\"  Output features: {model.fc.out_features} (ImageNet classes)\")\n",
    "\n",
    "# Replace with our custom classifier\n",
    "# The in_features must match (512 for ResNet-18's final feature size)\n",
    "# The NUM_CLASSES will change for other datasets\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "print(\"\\n New FC layer:\")\n",
    "print(f\"  Input features: {model.fc.in_features}\")\n",
    "print(f\"  Output features: {model.fc.out_features} (our classes)\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657bdac",
   "metadata": {},
   "source": [
    "### Freezing and Unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44b172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Freezing entire model...\n",
      "  ResNet: 11,191,389 parameters FROZEN\n",
      "\n",
      " Unfreezing only the FC layer...\n",
      "  Linear: 14,877 parameters UNFROZEN (trainable)\n",
      "\n",
      " Trainable: 14,877 / 11,191,389 parameters (0.132933%)\n"
     ]
    }
   ],
   "source": [
    "def set_requires_grad(module: nn.Module, requires_grad: bool):\n",
    "    \"\"\"\n",
    "    Recursively set requires_grad for all parameters in a module.\n",
    "    \n",
    "    Args:\n",
    "        module: PyTorch module (layer, block, or entire model)\n",
    "        requires_grad: True to unfreeze (train), False to freeze\n",
    "    \"\"\"\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = requires_grad\n",
    "    \n",
    "    # Print status\n",
    "    param_count = sum(p.numel() for p in module.parameters())\n",
    "    status = \"UNFROZEN (trainable)\" if requires_grad else \"FROZEN\"\n",
    "    print(f\"  {module.__class__.__name__}: {param_count:,} parameters {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63f4ef",
   "metadata": {},
   "source": [
    "### Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1f09902",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    \"\"\"\n",
    "    Train for one epoch.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy)\n",
    "    \"\"\"\n",
    "    model.train()  # Enable dropout, batch norm training mode\n",
    "    \n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        # Move data to device (GPU/CPU)\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        # Track metrics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        correct_predictions += (predictions == labels).sum().item()\n",
    "        total_samples += images.size(0)\n",
    "        \n",
    "        # Optional: Print progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"    Batch {batch_idx}/{len(loader)}, \"\n",
    "                  f\"Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = running_loss / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "@torch.no_grad()  # Decorator disables gradient computation\n",
    "def evaluate(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate model on validation/test set.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy)\n",
    "    \"\"\"\n",
    "    model.eval()  # Disable dropout, batch norm eval mode\n",
    "    \n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        # Forward pass only (no backward)\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Track metrics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        correct_predictions += (predictions == labels).sum().item()\n",
    "        total_samples += images.size(0)\n",
    "    \n",
    "    avg_loss = running_loss / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b3367",
   "metadata": {},
   "source": [
    "### Phase 1.1: Head-Only Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8720921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " PHASE 1: HEAD-ONLY FINE-TUNING\n",
      "============================================================\n",
      "\n",
      " Freezing all layers...\n",
      "  ResNet: 11,191,389 parameters FROZEN\n",
      "\n",
      " Unfreezing classifier head...\n",
      "  Linear: 14,877 parameters UNFROZEN (trainable)\n",
      "\n",
      " Optimizer setup:\n",
      "   Learning rate: 0.001\n",
      "   Trainable params: 14,877\n",
      "\n",
      " Training progress:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Epoch 1/3\n",
      "    Batch 0/2, Loss: 3.5293\n",
      "   Train: Loss=3.5571, Acc=0.026\n",
      "   Val:   Loss=3.3233, Acc=0.103  New best!\n",
      "\n",
      "Epoch 2/3\n",
      "    Batch 0/2, Loss: 3.3060\n",
      "   Train: Loss=3.2733, Acc=0.086\n",
      "   Val:   Loss=3.1990, Acc=0.103  New best!\n",
      "\n",
      "Epoch 3/3\n",
      "    Batch 0/2, Loss: 3.1617\n",
      "   Train: Loss=3.0907, Acc=0.216\n",
      "   Val:   Loss=3.0888, Acc=0.172  New best!\n",
      "\n",
      " Phase 1 Complete!\n",
      "   Best validation accuracy: 0.172\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for Phase 1\n",
    "EPOCHS_HEAD_ONLY = 3    \n",
    "LR_HEAD = 1e-3          \n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" PHASE 1: HEAD-ONLY FINE-TUNING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Freeze entire model\n",
    "print(\"\\n Freezing all layers...\")\n",
    "set_requires_grad(model, False)\n",
    "\n",
    "# Step 2: Unfreeze only the classifier head\n",
    "print(\"\\n Unfreezing classifier head...\")\n",
    "set_requires_grad(model.fc, True)\n",
    "\n",
    "# Step 3: Create optimizer for ONLY trainable parameters\n",
    "# filter() ensures we only optimize parameters with requires_grad=True\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(trainable_params, lr=LR_HEAD)\n",
    "\n",
    "print(f\"\\n Optimizer setup:\")\n",
    "print(f\"   Learning rate: {LR_HEAD}\")\n",
    "print(f\"   Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Step 4: Training loop\n",
    "print(\"\\n Training progress:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(1, EPOCHS_HEAD_ONLY + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS_HEAD_ONLY}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = evaluate(model, val_loader)\n",
    "    \n",
    "    # Track best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        # Optional: Save best model\n",
    "        # torch.save(model.state_dict(), 'best_model_phase1.pth')\n",
    "    \n",
    "    print(f\"   Train: Loss={train_loss:.4f}, Acc={train_acc:.3f}\")\n",
    "    print(f\"   Val:   Loss={val_loss:.4f}, Acc={val_acc:.3f} \"\n",
    "          f\"{' New best!' if val_acc == best_val_acc else ''}\")\n",
    "\n",
    "print(\"\\n Phase 1 Complete!\")\n",
    "print(f\"   Best validation accuracy: {best_val_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
